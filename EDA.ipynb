{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Loaded ISIC dataset with 33126 rows and 8 columns\n",
      "Loaded synthetic dataset with 33126 rows and 18 columns\n",
      "Note: The following columns exist in both datasets and will be taken from the ISIC dataset: ['target', 'benign_malignant']\n",
      "Successfully merged datasets. Result has 33126 rows and 23 columns\n",
      "Warning: The merged dataset contains 660 missing values\n",
      "Merged dataset saved to complete_cancer_detection_dataset.csv\n",
      "\n",
      "First 5 rows of the merged dataset:\n",
      "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n",
      "0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n",
      "1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n",
      "2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n",
      "3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n",
      "4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n",
      "\n",
      "  diagnosis benign_malignant  target  traditional_diagnosis_time  \\\n",
      "0   unknown           benign       0                        93.6   \n",
      "1   unknown           benign       0                        66.8   \n",
      "2     nevus           benign       0                        79.8   \n",
      "3   unknown           benign       0                       108.3   \n",
      "4   unknown           benign       0                        65.7   \n",
      "\n",
      "   ai_diagnosis_time  ...  tech_readiness_score traditional_total_cost  \\\n",
      "0               27.7  ...                  91.4                  450.0   \n",
      "1               32.3  ...                  89.7                  551.0   \n",
      "2               16.2  ...                  74.6                  555.0   \n",
      "3               32.4  ...                  80.4                  344.0   \n",
      "4               19.7  ...                  82.3                  465.0   \n",
      "\n",
      "  ai_total_cost  cost_difference_percentage  traditional_survival_probability  \\\n",
      "0         563.0                       -25.1                              96.9   \n",
      "1         456.0                        17.2                              97.0   \n",
      "2        1022.0                       -84.1                              97.3   \n",
      "3         510.0                       -48.3                              98.0   \n",
      "4         517.0                       -11.2                              99.4   \n",
      "\n",
      "   ai_survival_probability  survival_probability_improvement  \\\n",
      "0                     99.0                               2.1   \n",
      "1                     99.7                               2.7   \n",
      "2                     99.8                               2.5   \n",
      "3                     98.2                               0.2   \n",
      "4                     98.2                              -1.3   \n",
      "\n",
      "   traditional_efficiency_score  ai_efficiency_score  efficiency_improvement  \n",
      "0                           5.8                  7.7                     1.9  \n",
      "1                           5.1                  7.8                     2.7  \n",
      "2                           6.0                  7.6                     1.6  \n",
      "3                           5.4                  7.3                     1.9  \n",
      "4                           6.4                  9.0                     2.6  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_data_files():\n",
    "    \"\"\"\n",
    "    Merge the ISIC_2020_Training_GroundTruth.csv with merged_sample.csv\n",
    "    using image_name as the common key.\n",
    "    \"\"\"\n",
    "    print(\"Loading datasets...\")\n",
    "    \n",
    "    try:\n",
    "        # Load the original ISIC dataset\n",
    "        isic_df = pd.read_csv('ISIC_2020_Training_GroundTruth.csv')\n",
    "        print(f\"Loaded ISIC dataset with {len(isic_df)} rows and {len(isic_df.columns)} columns\")\n",
    "        \n",
    "        # Load the synthetic data\n",
    "        synthetic_df = pd.read_csv('merged_sample.csv')\n",
    "        print(f\"Loaded synthetic dataset with {len(synthetic_df)} rows and {len(synthetic_df.columns)} columns\")\n",
    "        \n",
    "        # Check if both datasets have the image_name column\n",
    "        if 'image_name' not in isic_df.columns:\n",
    "            print(\"Error: 'image_name' column not found in ISIC_2020_Training_GroundTruth.csv\")\n",
    "            return\n",
    "            \n",
    "        if 'image_name' not in synthetic_df.columns:\n",
    "            print(\"Error: 'image_name' column not found in merged_sample.csv\")\n",
    "            return\n",
    "        \n",
    "        # Identify columns that exist in both datasets (to avoid duplication)\n",
    "        duplicate_cols = [col for col in synthetic_df.columns if col in isic_df.columns and col != 'image_name']\n",
    "        if duplicate_cols:\n",
    "            print(f\"Note: The following columns exist in both datasets and will be taken from the ISIC dataset: {duplicate_cols}\")\n",
    "            # Remove duplicate columns from synthetic_df to avoid _x, _y suffixes\n",
    "            synthetic_df = synthetic_df.drop(columns=duplicate_cols)\n",
    "        \n",
    "        # Merge the datasets on image_name\n",
    "        merged_df = pd.merge(isic_df, synthetic_df, on='image_name', how='left')\n",
    "        print(f\"Successfully merged datasets. Result has {len(merged_df)} rows and {len(merged_df.columns)} columns\")\n",
    "        \n",
    "        # Check for any missing values that might have been introduced during the merge\n",
    "        missing_count = merged_df.isnull().sum().sum()\n",
    "        if missing_count > 0:\n",
    "            print(f\"Warning: The merged dataset contains {missing_count} missing values\")\n",
    "        \n",
    "        # Save the merged data\n",
    "        output_filename = 'complete_cancer_detection_dataset.csv'\n",
    "        merged_df.to_csv(output_filename, index=False)\n",
    "        print(f\"Merged dataset saved to {output_filename}\")\n",
    "        \n",
    "        # Display the first few rows of the merged dataset\n",
    "        print(\"\\nFirst 5 rows of the merged dataset:\")\n",
    "        print(merged_df.head())\n",
    "        \n",
    "        return merged_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during merge process: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    merge_data_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded with 33126 rows and 23 columns\n",
      "\n",
      "===== BASIC DATASET EXPLORATION =====\n",
      "\n",
      "Data types and missing values:\n",
      "                                 Data Type  Missing Values  Missing Percentage\n",
      "image_name                          object               0                0.00\n",
      "patient_id                          object               0                0.00\n",
      "sex                                 object              65                0.20\n",
      "age_approx                         float64              68                0.21\n",
      "anatom_site_general_challenge       object             527                1.59\n",
      "diagnosis                           object               0                0.00\n",
      "benign_malignant                    object               0                0.00\n",
      "target                               int64               0                0.00\n",
      "traditional_diagnosis_time         float64               0                0.00\n",
      "ai_diagnosis_time                  float64               0                0.00\n",
      "time_saved_percentage              float64               0                0.00\n",
      "country                             object               0                0.00\n",
      "hospital_tier                       object               0                0.00\n",
      "tech_readiness_score               float64               0                0.00\n",
      "traditional_total_cost             float64               0                0.00\n",
      "ai_total_cost                      float64               0                0.00\n",
      "cost_difference_percentage         float64               0                0.00\n",
      "traditional_survival_probability   float64               0                0.00\n",
      "ai_survival_probability            float64               0                0.00\n",
      "survival_probability_improvement   float64               0                0.00\n",
      "traditional_efficiency_score       float64               0                0.00\n",
      "ai_efficiency_score                float64               0                0.00\n",
      "efficiency_improvement             float64               0                0.00\n",
      "\n",
      "Summary statistics for numerical columns:\n",
      "                                    count        mean         std     min  \\\n",
      "age_approx                        33058.0   48.870016   14.380360     0.0   \n",
      "target                            33126.0    0.017630    0.131603     0.0   \n",
      "traditional_diagnosis_time        33126.0   69.054954   13.181869    24.0   \n",
      "ai_diagnosis_time                 33126.0   23.599973    5.855233    12.0   \n",
      "time_saved_percentage             33126.0   64.660958   10.993189   -55.8   \n",
      "tech_readiness_score              33126.0   82.780755    8.934421    34.3   \n",
      "traditional_total_cost            33126.0  627.349755  387.677360   220.0   \n",
      "ai_total_cost                     33126.0  577.380939  164.736145   345.0   \n",
      "cost_difference_percentage        33126.0   -4.146305   41.650550 -1819.5   \n",
      "traditional_survival_probability  33126.0   97.476867    4.411612    25.4   \n",
      "ai_survival_probability           33126.0   98.481048    4.317354    26.4   \n",
      "survival_probability_improvement  33126.0    1.004616    1.109873    -3.6   \n",
      "traditional_efficiency_score      33126.0    6.000999    1.002963     1.7   \n",
      "ai_efficiency_score               33126.0    8.282911    0.806744     4.8   \n",
      "efficiency_improvement            33126.0    2.281911    1.279755    -3.4   \n",
      "\n",
      "                                    25%    50%    75%     max  \n",
      "age_approx                         40.0   50.0   60.0    90.0  \n",
      "target                              0.0    0.0    0.0     1.0  \n",
      "traditional_diagnosis_time         60.2   68.3   76.9   141.6  \n",
      "ai_diagnosis_time                  19.5   23.5   27.5    47.2  \n",
      "time_saved_percentage              58.4   65.8   72.4    90.4  \n",
      "tech_readiness_score               77.5   84.5   89.5   100.0  \n",
      "traditional_total_cost            470.0  523.0  615.0  8955.0  \n",
      "ai_total_cost                     516.0  553.0  593.0  7344.0  \n",
      "cost_difference_percentage        -20.5   -5.1   14.5    94.6  \n",
      "traditional_survival_probability   97.3   98.0   98.7   101.8  \n",
      "ai_survival_probability            98.6   99.0   99.3   100.8  \n",
      "survival_probability_improvement    0.3    1.0    1.7     5.5  \n",
      "traditional_efficiency_score        5.3    6.0    6.7    10.0  \n",
      "ai_efficiency_score                 7.8    8.3    8.8    10.0  \n",
      "efficiency_improvement              1.4    2.3    3.1     7.1  \n",
      "\n",
      "Target variable distribution:\n",
      "0 (Benign): 32542 (98.24%)\n",
      "1 (Malignant): 584 (1.76%)\n",
      "\n",
      "Unique values in categorical columns:\n",
      "\n",
      "image_name - 33126 unique values:\n",
      "  Top 5 values:\n",
      "  ISIC_9999806: 1 (0.00%)\n",
      "  ISIC_2637011: 1 (0.00%)\n",
      "  ISIC_0015719: 1 (0.00%)\n",
      "  ISIC_0052212: 1 (0.00%)\n",
      "  ISIC_0068279: 1 (0.00%)\n",
      "\n",
      "patient_id - 2056 unique values:\n",
      "  Top 5 values:\n",
      "  IP_7279968: 115 (0.35%)\n",
      "  IP_4382720: 115 (0.35%)\n",
      "  IP_4938382: 115 (0.35%)\n",
      "  IP_4479736: 115 (0.35%)\n",
      "  IP_0656529: 114 (0.34%)\n",
      "\n",
      "sex - 2 unique values:\n",
      "  male: 17080 (51.56%)\n",
      "  female: 15981 (48.24%)\n",
      "\n",
      "anatom_site_general_challenge - 6 unique values:\n",
      "  torso: 16845 (50.85%)\n",
      "  lower extremity: 8417 (25.41%)\n",
      "  upper extremity: 4983 (15.04%)\n",
      "  head/neck: 1855 (5.60%)\n",
      "  palms/soles: 375 (1.13%)\n",
      "  oral/genital: 124 (0.37%)\n",
      "\n",
      "diagnosis - 9 unique values:\n",
      "  unknown: 27124 (81.88%)\n",
      "  nevus: 5193 (15.68%)\n",
      "  melanoma: 584 (1.76%)\n",
      "  seborrheic keratosis: 135 (0.41%)\n",
      "  lentigo NOS: 44 (0.13%)\n",
      "  lichenoid keratosis: 37 (0.11%)\n",
      "  solar lentigo: 7 (0.02%)\n",
      "  cafe-au-lait macule: 1 (0.00%)\n",
      "  atypical melanocytic proliferation: 1 (0.00%)\n",
      "\n",
      "benign_malignant - 2 unique values:\n",
      "  benign: 32542 (98.24%)\n",
      "  malignant: 584 (1.76%)\n",
      "\n",
      "country - 10 unique values:\n",
      "  Top 5 values:\n",
      "  Finland: 3403 (10.27%)\n",
      "  Spain: 3403 (10.27%)\n",
      "  Poland: 3381 (10.21%)\n",
      "  Netherlands: 3335 (10.07%)\n",
      "  Germany: 3307 (9.98%)\n",
      "\n",
      "hospital_tier - 4 unique values:\n",
      "  Secondary: 11599 (35.01%)\n",
      "  Tertiary: 8402 (25.36%)\n",
      "  Primary: 8178 (24.69%)\n",
      "  University: 4947 (14.93%)\n",
      "\n",
      "===== CLINICAL DATA ANALYSIS =====\n",
      "\n",
      "Diagnosis distribution:\n",
      "  unknown: 27124 (81.88%)\n",
      "  nevus: 5193 (15.68%)\n",
      "  melanoma: 584 (1.76%)\n",
      "  seborrheic keratosis: 135 (0.41%)\n",
      "  lentigo NOS: 44 (0.13%)\n",
      "  lichenoid keratosis: 37 (0.11%)\n",
      "  solar lentigo: 7 (0.02%)\n",
      "  cafe-au-lait macule: 1 (0.00%)\n",
      "  atypical melanocytic proliferation: 1 (0.00%)\n",
      "\n",
      "Anatomical site distribution:\n",
      "  torso: 16845 (50.85%)\n",
      "  lower extremity: 8417 (25.41%)\n",
      "  upper extremity: 4983 (15.04%)\n",
      "  head/neck: 1855 (5.60%)\n",
      "  palms/soles: 375 (1.13%)\n",
      "  oral/genital: 124 (0.37%)\n",
      "\n",
      "Benign/malignant distribution:\n",
      "  benign: 32542 (98.24%)\n",
      "  malignant: 584 (1.76%)\n",
      "\n",
      "Age statistics:\n",
      "  Mean age: 48.87\n",
      "  Median age: 50.00\n",
      "  Min age: 0.00\n",
      "  Max age: 90.00\n",
      "\n",
      "Age by benign/malignant status:\n",
      "                       mean  median   min   max\n",
      "benign_malignant                               \n",
      "benign            48.703424    50.0   0.0  90.0\n",
      "malignant         58.133562    60.0  15.0  90.0\n",
      "\n",
      "Gender by benign/malignant status:\n",
      "benign_malignant     benign  malignant\n",
      "sex                                   \n",
      "female            98.623365   1.376635\n",
      "male              97.868852   2.131148\n",
      "\n",
      "Target distribution by anatomical site:\n",
      "target                                 0         1\n",
      "anatom_site_general_challenge                     \n",
      "head/neck                      96.010782  3.989218\n",
      "lower extremity                98.526791  1.473209\n",
      "oral/genital                   96.774194  3.225806\n",
      "palms/soles                    98.666667  1.333333\n",
      "torso                          98.474325  1.525675\n",
      "upper extremity                97.772426  2.227574\n",
      "\n",
      "Average age by diagnosis:\n",
      "diagnosis\n",
      "solar lentigo                         65.714286\n",
      "lichenoid keratosis                   65.135135\n",
      "seborrheic keratosis                  62.851852\n",
      "lentigo NOS                           61.363636\n",
      "melanoma                              58.133562\n",
      "atypical melanocytic proliferation    55.000000\n",
      "cafe-au-lait macule                   55.000000\n",
      "nevus                                 49.747592\n",
      "unknown                               48.384641\n",
      "Name: age_approx, dtype: float64\n",
      "\n",
      "===== AI VS TRADITIONAL COMPARISON ANALYSIS =====\n",
      "\n",
      "Diagnostic time comparison:\n",
      "  Traditional method average time: 69.05 hours\n",
      "  AI-assisted method average time: 23.60 hours\n",
      "  Time reduction: 45.45 hours (65.82%)\n",
      "\n",
      "Time saved percentage statistics:\n",
      "  Mean: 64.66%\n",
      "  Median: 65.80%\n",
      "  Min: -55.80%\n",
      "  Max: 90.40%\n",
      "\n",
      "Cost comparison:\n",
      "  Traditional method average cost: 627.35 EUR\n",
      "  AI-assisted method average cost: 577.38 EUR\n",
      "  Cost difference: 49.97 EUR (7.97%)\n",
      "\n",
      "Cost difference percentage statistics:\n",
      "  Mean: -4.15%\n",
      "  Median: -5.10%\n",
      "  Min: -1819.50%\n",
      "  Max: 94.60%\n",
      "\n",
      "Survival probability comparison:\n",
      "  Traditional method average survival probability: 97.48%\n",
      "  AI-assisted method average survival probability: 98.48%\n",
      "  Survival probability improvement: 1.00 percentage points\n",
      "\n",
      "Survival probability improvement statistics:\n",
      "  Mean: 1.00 points\n",
      "  Median: 1.00 points\n",
      "  Min: -3.60 points\n",
      "  Max: 5.50 points\n",
      "\n",
      "Efficiency score comparison:\n",
      "  Traditional method average efficiency score: 6.00\n",
      "  AI-assisted method average efficiency score: 8.28\n",
      "  Efficiency score improvement: 2.28 points\n",
      "\n",
      "Statistical comparison of traditional vs AI methods:\n",
      "  Diagnostic time: t=594.4919, p=0.00000000 - Significant\n",
      "  Cost: t=22.1139, p=0.00000000 - Significant\n",
      "  Survival probability: t=-164.7298, p=0.00000000 - Significant\n",
      "  Efficiency score: t=-324.5312, p=0.00000000 - Significant\n",
      "\n",
      "Summary of improvements with AI-assisted diagnosis:\n",
      "  Time reduction: 65.82%\n",
      "  Cost change: 7.97%\n",
      "  Survival probability improvement: 1.00 percentage points\n",
      "  Efficiency score improvement: 2.28 points\n",
      "\n",
      "===== GEOGRAPHIC AND HEALTHCARE SYSTEM ANALYSIS =====\n",
      "\n",
      "Technology readiness by country:\n",
      "  Denmark: 92.09\n",
      "  Sweden: 89.96\n",
      "  Netherlands: 88.10\n",
      "  Finland: 87.94\n",
      "  Germany: 85.00\n",
      "  Belgium: 82.02\n",
      "  France: 79.88\n",
      "  Spain: 78.00\n",
      "  Italy: 75.10\n",
      "  Poland: 70.16\n",
      "\n",
      "Time saved percentage by country:\n",
      "  France: 64.87%\n",
      "  Netherlands: 64.82%\n",
      "  Finland: 64.72%\n",
      "  Spain: 64.72%\n",
      "  Belgium: 64.68%\n",
      "  Germany: 64.65%\n",
      "  Italy: 64.64%\n",
      "  Sweden: 64.55%\n",
      "  Denmark: 64.51%\n",
      "  Poland: 64.44%\n",
      "\n",
      "Efficiency improvement by hospital tier:\n",
      "  University: 2.79 points\n",
      "  Tertiary: 2.54 points\n",
      "  Secondary: 2.20 points\n",
      "  Primary: 1.83 points\n",
      "\n",
      "Correlation between technology readiness and improvement metrics:\n",
      "tech_readiness_score                1.000000\n",
      "efficiency_improvement              0.381280\n",
      "survival_probability_improvement    0.003494\n",
      "time_saved_percentage               0.001241\n",
      "cost_difference_percentage         -0.003363\n",
      "Name: tech_readiness_score, dtype: float64\n",
      "\n",
      "Hospital tier distribution:\n",
      "  Secondary: 11599 (35.01%)\n",
      "  Tertiary: 8402 (25.36%)\n",
      "  Primary: 8178 (24.69%)\n",
      "  University: 4947 (14.93%)\n",
      "\n",
      "===== HYPOTHESIS TESTING =====\n",
      "Research Hypothesis: Implementation of standardized AI-assisted diagnostic imaging systems in EU hospitals will increase cancer detection accuracy by 15% and reduce diagnostic time from 72 to 24 hours.\n",
      "\n",
      "1. Time Reduction Analysis:\n",
      "   - Average traditional diagnostic time: 69.05 hours\n",
      "   - Average AI-assisted diagnostic time: 23.60 hours\n",
      "   - Time reduction: 45.45 hours (65.82%)\n",
      "   - T-test comparing AI diagnostic time to 24 hours: t=-12.4345, p=0.00000000\n",
      "   - Conclusion: AI diagnostic time is significantly different from 24 hours\n",
      "\n",
      "2. Improvement by Diagnosis Category:\n",
      "   Survival probability improvement:\n",
      "   - Lentigo: 1.20 percentage points\n",
      "   - Keratosis: 1.11 percentage points\n",
      "   - Melanoma: 1.08 percentage points\n",
      "   - Nevus: 1.01 percentage points\n",
      "   - Other: 1.00 percentage points\n",
      "\n",
      "   Time saved percentage:\n",
      "   - Keratosis: 66.48%\n",
      "   - Melanoma: 65.73%\n",
      "   - Other: 64.70%\n",
      "   - Nevus: 64.28%\n",
      "   - Lentigo: 63.55%\n",
      "\n",
      "3. Technology Readiness and Benefits:\n",
      "   Correlation between tech readiness and time saved: 0.0012\n",
      "   Correlation between tech readiness and survival improvement: 0.0035\n",
      "\n",
      "4. Malignant Case Analysis:\n",
      "   - Number of malignant cases: 584\n",
      "   - Time reduction for malignant cases: 66.73%\n",
      "   - Survival probability improvement for malignant cases: 1.08 percentage points\n",
      "\n",
      "Hypothesis Testing Conclusion:\n",
      "✗ The data does not fully support the hypothesis about reducing diagnostic time from 72 to 24 hours.\n",
      "  Actual reduction: 65.82% (vs. required 66.67%)\n",
      "\n",
      "Summary statistics:\n",
      "                                        Metric      Value\n",
      "0  Average Traditional Diagnostic Time (hours)  69.054954\n",
      "1  Average AI-Assisted Diagnostic Time (hours)  23.599973\n",
      "2                           Time Reduction (%)  65.824359\n",
      "3           Average Technology Readiness Score  82.780755\n",
      "4     Average Survival Probability Improvement   1.004616\n",
      "5                  Average Cost Difference (%)  -4.146305\n",
      "\n",
      "===== CORRELATION ANALYSIS =====\n",
      "\n",
      "Correlations with target variable (cancer diagnosis):\n",
      "  traditional_total_cost: 0.3154\n",
      "  traditional_diagnosis_time: 0.0903\n",
      "  age_approx: 0.0864\n",
      "  ai_total_cost: 0.0819\n",
      "  ai_diagnosis_time: 0.0533\n",
      "  time_saved_percentage: 0.0130\n",
      "  survival_probability_improvement: 0.0094\n",
      "  efficiency_improvement: 0.0036\n",
      "  tech_readiness_score: 0.0001\n",
      "  ai_efficiency_score: -0.0036\n",
      "  traditional_efficiency_score: -0.0076\n",
      "  cost_difference_percentage: -0.0255\n",
      "  traditional_survival_probability: -0.8817\n",
      "  ai_survival_probability: -0.8985\n",
      "\n",
      "Correlations with time saved percentage:\n",
      "  traditional_diagnosis_time: 0.5544\n",
      "  ai_total_cost: 0.0138\n",
      "  target: 0.0130\n",
      "  survival_probability_improvement: 0.0108\n",
      "  ai_efficiency_score: 0.0037\n",
      "  traditional_total_cost: 0.0035\n",
      "  efficiency_improvement: 0.0016\n",
      "  age_approx: 0.0014\n",
      "  tech_readiness_score: 0.0012\n",
      "  traditional_efficiency_score: 0.0010\n",
      "  cost_difference_percentage: -0.0104\n",
      "  ai_survival_probability: -0.0117\n",
      "  traditional_survival_probability: -0.0143\n",
      "  ai_diagnosis_time: -0.7406\n",
      "\n",
      "Correlations with survival probability improvement:\n",
      "  ai_survival_probability: 0.0425\n",
      "  time_saved_percentage: 0.0108\n",
      "  traditional_diagnosis_time: 0.0097\n",
      "  target: 0.0094\n",
      "  traditional_total_cost: 0.0058\n",
      "  ai_efficiency_score: 0.0043\n",
      "  efficiency_improvement: 0.0039\n",
      "  cost_difference_percentage: 0.0039\n",
      "  tech_readiness_score: 0.0035\n",
      "  age_approx: 0.0012\n",
      "  ai_total_cost: -0.0004\n",
      "  traditional_efficiency_score: -0.0016\n",
      "  ai_diagnosis_time: -0.0067\n",
      "  traditional_survival_probability: -0.2096\n",
      "\n",
      "Correlations with efficiency improvement:\n",
      "  ai_efficiency_score: 0.6212\n",
      "  tech_readiness_score: 0.3813\n",
      "  cost_difference_percentage: 0.0073\n",
      "  traditional_total_cost: 0.0046\n",
      "  survival_probability_improvement: 0.0039\n",
      "  target: 0.0036\n",
      "  time_saved_percentage: 0.0016\n",
      "  age_approx: 0.0013\n",
      "  ai_survival_probability: -0.0005\n",
      "  traditional_survival_probability: -0.0015\n",
      "  ai_diagnosis_time: -0.0019\n",
      "  traditional_diagnosis_time: -0.0034\n",
      "  ai_total_cost: -0.0075\n",
      "  traditional_efficiency_score: -0.7763\n",
      "\n",
      "Top 10 strongest correlations overall:\n",
      "  traditional_survival_probability & ai_survival_probability: 0.9679\n",
      "  target & ai_survival_probability: 0.8985\n",
      "  target & traditional_survival_probability: 0.8817\n",
      "  traditional_efficiency_score & efficiency_improvement: 0.7763\n",
      "  ai_diagnosis_time & time_saved_percentage: 0.7406\n",
      "  ai_total_cost & cost_difference_percentage: 0.6457\n",
      "  ai_efficiency_score & efficiency_improvement: 0.6212\n",
      "  tech_readiness_score & ai_efficiency_score: 0.6142\n",
      "  traditional_diagnosis_time & time_saved_percentage: 0.5544\n",
      "  traditional_total_cost & cost_difference_percentage: 0.4706\n",
      "\n",
      "===== COST-BENEFIT ANALYSIS =====\n",
      "\n",
      "Overall cost comparison:\n",
      "  Traditional method average cost: 627.35 EUR\n",
      "  AI-assisted method average cost: 577.38 EUR\n",
      "  Average cost difference: 49.97 EUR (7.97%)\n",
      "\n",
      "Time efficiency:\n",
      "  Traditional method average time: 69.05 hours\n",
      "  AI-assisted method average time: 23.60 hours\n",
      "  Average time saved: 45.45 hours (65.82%)\n",
      "\n",
      "Staff resource efficiency:\n",
      "  Estimated staff time saved: 52.66%\n",
      "\n",
      "Cost analysis by hospital tier:\n",
      "               traditional_total_cost  ai_total_cost  \\\n",
      "hospital_tier                                          \n",
      "Primary                    621.836390     579.219491   \n",
      "Secondary                  630.022071     576.356669   \n",
      "Tertiary                   629.504166     576.785289   \n",
      "University                 626.539317     577.754801   \n",
      "\n",
      "               cost_difference_percentage  \n",
      "hospital_tier                              \n",
      "Primary                         -4.591514  \n",
      "Secondary                       -4.011932  \n",
      "Tertiary                        -3.869495  \n",
      "University                      -4.195512  \n",
      "\n",
      "Cost analysis by country:\n",
      "             traditional_total_cost  ai_total_cost  cost_difference_percentage\n",
      "country                                                                       \n",
      "Belgium                  627.559196     578.516847                   -4.664297\n",
      "Denmark                  633.565298     575.090769                   -3.127015\n",
      "Finland                  626.608581     573.900088                   -2.879342\n",
      "France                   630.620679     574.824439                   -3.754942\n",
      "Germany                  613.849410     578.942244                   -4.957031\n",
      "Italy                    628.688149     576.131032                   -3.532804\n",
      "Netherlands              628.653073     579.649175                   -4.397331\n",
      "Poland                   629.456965     577.433008                   -4.399793\n",
      "Spain                    629.512489     579.757861                   -4.470320\n",
      "Sweden                   624.999077     579.570901                   -5.302461\n",
      "\n",
      "Estimated annual cost impact:\n",
      "  Estimated annual cases: 67172\n",
      "  Estimated annual savings: 3356513.64 EUR\n",
      "\n",
      "Cost-effectiveness analysis:\n",
      "  Average survival probability improvement: 1.00 percentage points\n",
      "  Cost per percentage point improvement: -49.74 EUR (saving)\n",
      "\n",
      "===== EDA COMPLETE =====\n",
      "All analyses have been completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def load_data(file_path='complete_cancer_detection_dataset.csv'):\n",
    "    \"\"\"\n",
    "    Load the dataset and display basic information\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : str\n",
    "        Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        The loaded dataset\n",
    "    \"\"\"\n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Dataset loaded with {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "    return df\n",
    "\n",
    "def basic_eda(df):\n",
    "    \"\"\"\n",
    "    Perform basic exploratory data analysis\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The dataset to analyze\n",
    "    \"\"\"\n",
    "    print(\"\\n===== BASIC DATASET EXPLORATION =====\")\n",
    "    \n",
    "    # Data types and missing values\n",
    "    print(\"\\nData types and missing values:\")\n",
    "    missing_info = pd.DataFrame({\n",
    "        'Data Type': df.dtypes,\n",
    "        'Missing Values': df.isnull().sum(),\n",
    "        'Missing Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "    })\n",
    "    print(missing_info)\n",
    "    \n",
    "    # Check for extreme values or outliers in numerical columns\n",
    "    print(\"\\nSummary statistics for numerical columns:\")\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    print(df[num_cols].describe().T)\n",
    "    \n",
    "    # Display info about target variable\n",
    "    print(\"\\nTarget variable distribution:\")\n",
    "    target_counts = df['target'].value_counts()\n",
    "    target_pct = df['target'].value_counts(normalize=True) * 100\n",
    "    print(f\"0 (Benign): {target_counts[0]} ({target_pct[0]:.2f}%)\")\n",
    "    print(f\"1 (Malignant): {target_counts[1]} ({target_pct[1]:.2f}%)\")\n",
    "    \n",
    "    # Display unique values for categorical columns\n",
    "    print(\"\\nUnique values in categorical columns:\")\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        value_counts = df[col].value_counts()\n",
    "        print(f\"\\n{col} - {len(value_counts)} unique values:\")\n",
    "        if len(value_counts) < 10:  # Only show if not too many unique values\n",
    "            for val, count in value_counts.items():\n",
    "                pct = count / len(df) * 100\n",
    "                print(f\"  {val}: {count} ({pct:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"  Top 5 values:\")\n",
    "            for val, count in value_counts.head().items():\n",
    "                pct = count / len(df) * 100\n",
    "                print(f\"  {val}: {count} ({pct:.2f}%)\")\n",
    "\n",
    "def clinical_analysis(df):\n",
    "    \"\"\"\n",
    "    Analyze the clinical aspects of the dataset\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The dataset to analyze\n",
    "    \"\"\"\n",
    "    print(\"\\n===== CLINICAL DATA ANALYSIS =====\")\n",
    "    \n",
    "    # Distribution of diagnosis\n",
    "    print(\"\\nDiagnosis distribution:\")\n",
    "    diagnosis_counts = df['diagnosis'].value_counts()\n",
    "    for diagnosis, count in diagnosis_counts.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"  {diagnosis}: {count} ({pct:.2f}%)\")\n",
    "    \n",
    "    # Distribution by anatomical site\n",
    "    print(\"\\nAnatomical site distribution:\")\n",
    "    site_counts = df['anatom_site_general_challenge'].value_counts()\n",
    "    for site, count in site_counts.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"  {site}: {count} ({pct:.2f}%)\")\n",
    "    \n",
    "    # Distribution by benign/malignant\n",
    "    print(\"\\nBenign/malignant distribution:\")\n",
    "    benign_malignant_counts = df['benign_malignant'].value_counts()\n",
    "    for status, count in benign_malignant_counts.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"  {status}: {count} ({pct:.2f}%)\")\n",
    "    \n",
    "    # Age statistics\n",
    "    print(\"\\nAge statistics:\")\n",
    "    print(f\"  Mean age: {df['age_approx'].mean():.2f}\")\n",
    "    print(f\"  Median age: {df['age_approx'].median():.2f}\")\n",
    "    print(f\"  Min age: {df['age_approx'].min():.2f}\")\n",
    "    print(f\"  Max age: {df['age_approx'].max():.2f}\")\n",
    "    \n",
    "    # Age distribution by benign/malignant\n",
    "    print(\"\\nAge by benign/malignant status:\")\n",
    "    age_by_status = df.groupby('benign_malignant')['age_approx'].agg(['mean', 'median', 'min', 'max'])\n",
    "    print(age_by_status)\n",
    "    \n",
    "    # Gender distribution by benign/malignant\n",
    "    print(\"\\nGender by benign/malignant status:\")\n",
    "    gender_malignant = pd.crosstab(df['sex'], df['benign_malignant'], normalize='index') * 100\n",
    "    print(gender_malignant)\n",
    "    \n",
    "    # Anatomical site by target\n",
    "    print(\"\\nTarget distribution by anatomical site:\")\n",
    "    site_target = pd.crosstab(df['anatom_site_general_challenge'], df['target'])\n",
    "    site_target_pct = site_target.div(site_target.sum(axis=1), axis=0) * 100\n",
    "    print(site_target_pct)\n",
    "    \n",
    "    # Average age by diagnosis\n",
    "    print(\"\\nAverage age by diagnosis:\")\n",
    "    print(df.groupby('diagnosis')['age_approx'].mean().sort_values(ascending=False))\n",
    "\n",
    "def ai_comparison_analysis(df):\n",
    "    \"\"\"\n",
    "    Analyze the comparison between traditional and AI-assisted diagnosis\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The dataset to analyze\n",
    "    \"\"\"\n",
    "    print(\"\\n===== AI VS TRADITIONAL COMPARISON ANALYSIS =====\")\n",
    "    \n",
    "    # Diagnostic time comparison\n",
    "    print(\"\\nDiagnostic time comparison:\")\n",
    "    trad_time_mean = df['traditional_diagnosis_time'].mean()\n",
    "    ai_time_mean = df['ai_diagnosis_time'].mean()\n",
    "    time_reduction = trad_time_mean - ai_time_mean\n",
    "    time_reduction_pct = (time_reduction / trad_time_mean) * 100\n",
    "    \n",
    "    print(f\"  Traditional method average time: {trad_time_mean:.2f} hours\")\n",
    "    print(f\"  AI-assisted method average time: {ai_time_mean:.2f} hours\")\n",
    "    print(f\"  Time reduction: {time_reduction:.2f} hours ({time_reduction_pct:.2f}%)\")\n",
    "    \n",
    "    # Time saved statistics\n",
    "    print(\"\\nTime saved percentage statistics:\")\n",
    "    print(f\"  Mean: {df['time_saved_percentage'].mean():.2f}%\")\n",
    "    print(f\"  Median: {df['time_saved_percentage'].median():.2f}%\")\n",
    "    print(f\"  Min: {df['time_saved_percentage'].min():.2f}%\")\n",
    "    print(f\"  Max: {df['time_saved_percentage'].max():.2f}%\")\n",
    "    \n",
    "    # Cost comparison\n",
    "    print(\"\\nCost comparison:\")\n",
    "    trad_cost_mean = df['traditional_total_cost'].mean()\n",
    "    ai_cost_mean = df['ai_total_cost'].mean()\n",
    "    cost_diff = trad_cost_mean - ai_cost_mean\n",
    "    cost_diff_pct = (cost_diff / trad_cost_mean) * 100\n",
    "    \n",
    "    print(f\"  Traditional method average cost: {trad_cost_mean:.2f} EUR\")\n",
    "    print(f\"  AI-assisted method average cost: {ai_cost_mean:.2f} EUR\")\n",
    "    print(f\"  Cost difference: {cost_diff:.2f} EUR ({cost_diff_pct:.2f}%)\")\n",
    "    \n",
    "    # Cost difference statistics\n",
    "    print(\"\\nCost difference percentage statistics:\")\n",
    "    print(f\"  Mean: {df['cost_difference_percentage'].mean():.2f}%\")\n",
    "    print(f\"  Median: {df['cost_difference_percentage'].median():.2f}%\")\n",
    "    print(f\"  Min: {df['cost_difference_percentage'].min():.2f}%\")\n",
    "    print(f\"  Max: {df['cost_difference_percentage'].max():.2f}%\")\n",
    "    \n",
    "    # Survival probability comparison\n",
    "    print(\"\\nSurvival probability comparison:\")\n",
    "    trad_survival_mean = df['traditional_survival_probability'].mean()\n",
    "    ai_survival_mean = df['ai_survival_probability'].mean()\n",
    "    survival_improvement = ai_survival_mean - trad_survival_mean\n",
    "    \n",
    "    print(f\"  Traditional method average survival probability: {trad_survival_mean:.2f}%\")\n",
    "    print(f\"  AI-assisted method average survival probability: {ai_survival_mean:.2f}%\")\n",
    "    print(f\"  Survival probability improvement: {survival_improvement:.2f} percentage points\")\n",
    "    \n",
    "    # Survival improvement statistics\n",
    "    print(\"\\nSurvival probability improvement statistics:\")\n",
    "    print(f\"  Mean: {df['survival_probability_improvement'].mean():.2f} points\")\n",
    "    print(f\"  Median: {df['survival_probability_improvement'].median():.2f} points\")\n",
    "    print(f\"  Min: {df['survival_probability_improvement'].min():.2f} points\")\n",
    "    print(f\"  Max: {df['survival_probability_improvement'].max():.2f} points\")\n",
    "    \n",
    "    # Efficiency score comparison\n",
    "    print(\"\\nEfficiency score comparison:\")\n",
    "    trad_efficiency_mean = df['traditional_efficiency_score'].mean()\n",
    "    ai_efficiency_mean = df['ai_efficiency_score'].mean()\n",
    "    efficiency_improvement = ai_efficiency_mean - trad_efficiency_mean\n",
    "    \n",
    "    print(f\"  Traditional method average efficiency score: {trad_efficiency_mean:.2f}\")\n",
    "    print(f\"  AI-assisted method average efficiency score: {ai_efficiency_mean:.2f}\")\n",
    "    print(f\"  Efficiency score improvement: {efficiency_improvement:.2f} points\")\n",
    "    \n",
    "    # Statistical testing\n",
    "    print(\"\\nStatistical comparison of traditional vs AI methods:\")\n",
    "    \n",
    "    # Time comparison\n",
    "    t_stat, p_val = stats.ttest_rel(df['traditional_diagnosis_time'], df['ai_diagnosis_time'])\n",
    "    print(f\"  Diagnostic time: t={t_stat:.4f}, p={p_val:.8f} - {'Significant' if p_val < 0.05 else 'Not significant'}\")\n",
    "    \n",
    "    # Cost comparison\n",
    "    t_stat, p_val = stats.ttest_rel(df['traditional_total_cost'], df['ai_total_cost'])\n",
    "    print(f\"  Cost: t={t_stat:.4f}, p={p_val:.8f} - {'Significant' if p_val < 0.05 else 'Not significant'}\")\n",
    "    \n",
    "    # Survival probability comparison\n",
    "    t_stat, p_val = stats.ttest_rel(df['traditional_survival_probability'], df['ai_survival_probability'])\n",
    "    print(f\"  Survival probability: t={t_stat:.4f}, p={p_val:.8f} - {'Significant' if p_val < 0.05 else 'Not significant'}\")\n",
    "    \n",
    "    # Efficiency score comparison\n",
    "    t_stat, p_val = stats.ttest_rel(df['traditional_efficiency_score'], df['ai_efficiency_score'])\n",
    "    print(f\"  Efficiency score: t={t_stat:.4f}, p={p_val:.8f} - {'Significant' if p_val < 0.05 else 'Not significant'}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nSummary of improvements with AI-assisted diagnosis:\")\n",
    "    print(f\"  Time reduction: {time_reduction_pct:.2f}%\")\n",
    "    print(f\"  Cost change: {cost_diff_pct:.2f}%\")\n",
    "    print(f\"  Survival probability improvement: {survival_improvement:.2f} percentage points\")\n",
    "    print(f\"  Efficiency score improvement: {efficiency_improvement:.2f} points\")\n",
    "\n",
    "def geographic_analysis(df):\n",
    "    \"\"\"\n",
    "    Analyze variations across different countries and healthcare systems\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The dataset to analyze\n",
    "    \"\"\"\n",
    "    print(\"\\n===== GEOGRAPHIC AND HEALTHCARE SYSTEM ANALYSIS =====\")\n",
    "    \n",
    "    # Technology readiness by country\n",
    "    print(\"\\nTechnology readiness by country:\")\n",
    "    country_tech = df.groupby('country')['tech_readiness_score'].mean().sort_values(ascending=False)\n",
    "    for country, score in country_tech.items():\n",
    "        print(f\"  {country}: {score:.2f}\")\n",
    "    \n",
    "    # Time saved by country\n",
    "    print(\"\\nTime saved percentage by country:\")\n",
    "    country_time = df.groupby('country')['time_saved_percentage'].mean().sort_values(ascending=False)\n",
    "    for country, time_saved in country_time.items():\n",
    "        print(f\"  {country}: {time_saved:.2f}%\")\n",
    "    \n",
    "    # Efficiency improvement by hospital tier\n",
    "    print(\"\\nEfficiency improvement by hospital tier:\")\n",
    "    tier_efficiency = df.groupby('hospital_tier')['efficiency_improvement'].mean().sort_values(ascending=False)\n",
    "    for tier, improvement in tier_efficiency.items():\n",
    "        print(f\"  {tier}: {improvement:.2f} points\")\n",
    "    \n",
    "    # Correlation between tech readiness and improvement metrics\n",
    "    print(\"\\nCorrelation between technology readiness and improvement metrics:\")\n",
    "    tech_metrics = df[['tech_readiness_score', 'time_saved_percentage', \n",
    "                     'cost_difference_percentage', 'survival_probability_improvement', \n",
    "                     'efficiency_improvement']]\n",
    "    correlation = tech_metrics.corr()\n",
    "    print(correlation['tech_readiness_score'].sort_values(ascending=False))\n",
    "    \n",
    "    # Hospital tier distribution\n",
    "    print(\"\\nHospital tier distribution:\")\n",
    "    tier_counts = df['hospital_tier'].value_counts()\n",
    "    for tier, count in tier_counts.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"  {tier}: {count} ({pct:.2f}%)\")\n",
    "\n",
    "def hypothesis_testing(df):\n",
    "    \"\"\"\n",
    "    Perform specific analyses to test the research hypothesis\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The dataset to analyze\n",
    "    \"\"\"\n",
    "    print(\"\\n===== HYPOTHESIS TESTING =====\")\n",
    "    print(\"Research Hypothesis: Implementation of standardized AI-assisted diagnostic imaging systems in EU hospitals will increase cancer detection accuracy by 15% and reduce diagnostic time from 72 to 24 hours.\")\n",
    "    \n",
    "    # 1. Check if diagnostic time is reduced from 72 to 24 hours\n",
    "    mean_trad_time = df['traditional_diagnosis_time'].mean()\n",
    "    mean_ai_time = df['ai_diagnosis_time'].mean()\n",
    "    time_reduction_pct = ((mean_trad_time - mean_ai_time) / mean_trad_time) * 100\n",
    "    \n",
    "    print(f\"\\n1. Time Reduction Analysis:\")\n",
    "    print(f\"   - Average traditional diagnostic time: {mean_trad_time:.2f} hours\")\n",
    "    print(f\"   - Average AI-assisted diagnostic time: {mean_ai_time:.2f} hours\")\n",
    "    print(f\"   - Time reduction: {mean_trad_time - mean_ai_time:.2f} hours ({time_reduction_pct:.2f}%)\")\n",
    "    \n",
    "    # Statistical test for time reduction\n",
    "    t_stat, p_val = stats.ttest_1samp(df['ai_diagnosis_time'], 24)\n",
    "    print(f\"   - T-test comparing AI diagnostic time to 24 hours: t={t_stat:.4f}, p={p_val:.8f}\")\n",
    "    print(f\"   - Conclusion: AI diagnostic time is {'not ' if p_val > 0.05 else ''}significantly different from 24 hours\")\n",
    "    \n",
    "    # 2. Analyze improvement by diagnosis category\n",
    "    # First, let's create a diagnosis category column based on the diagnosis\n",
    "    df['diagnosis_category'] = 'Other'\n",
    "    df.loc[df['diagnosis'] == 'melanoma', 'diagnosis_category'] = 'Melanoma'\n",
    "    df.loc[df['diagnosis'].str.contains('keratosis', case=False, na=False), 'diagnosis_category'] = 'Keratosis'\n",
    "    df.loc[df['diagnosis'] == 'nevus', 'diagnosis_category'] = 'Nevus'\n",
    "    df.loc[df['diagnosis'].str.contains('lentigo', case=False, na=False), 'diagnosis_category'] = 'Lentigo'\n",
    "    \n",
    "    # Calculate survival improvement by diagnosis category\n",
    "    category_survival = df.groupby('diagnosis_category')['survival_probability_improvement'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    # Calculate time saved by diagnosis category\n",
    "    category_time = df.groupby('diagnosis_category')['time_saved_percentage'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    # 3. Analyze relationship between adoption readiness and benefits\n",
    "    # Calculate correlation between readiness and benefits\n",
    "    correlation = df[['tech_readiness_score', 'time_saved_percentage', \n",
    "                     'survival_probability_improvement']].corr()\n",
    "    \n",
    "    print(\"\\n2. Improvement by Diagnosis Category:\")\n",
    "    print(f\"   Survival probability improvement:\")\n",
    "    for category, improvement in category_survival.items():\n",
    "        print(f\"   - {category}: {improvement:.2f} percentage points\")\n",
    "    \n",
    "    print(f\"\\n   Time saved percentage:\")\n",
    "    for category, time_saved in category_time.items():\n",
    "        print(f\"   - {category}: {time_saved:.2f}%\")\n",
    "    \n",
    "    print(\"\\n3. Technology Readiness and Benefits:\")\n",
    "    print(f\"   Correlation between tech readiness and time saved: {correlation.loc['tech_readiness_score', 'time_saved_percentage']:.4f}\")\n",
    "    print(f\"   Correlation between tech readiness and survival improvement: {correlation.loc['tech_readiness_score', 'survival_probability_improvement']:.4f}\")\n",
    "    \n",
    "    # 4. Analyze malignant case outcomes specifically\n",
    "    malignant_df = df[df['benign_malignant'] == 'malignant']\n",
    "    \n",
    "    malignant_time_reduction = ((malignant_df['traditional_diagnosis_time'].mean() - \n",
    "                               malignant_df['ai_diagnosis_time'].mean()) / \n",
    "                               malignant_df['traditional_diagnosis_time'].mean() * 100)\n",
    "    \n",
    "    malignant_survival_improvement = (malignant_df['ai_survival_probability'].mean() - \n",
    "                                    malignant_df['traditional_survival_probability'].mean())\n",
    "    \n",
    "    print(\"\\n4. Malignant Case Analysis:\")\n",
    "    print(f\"   - Number of malignant cases: {len(malignant_df)}\")\n",
    "    print(f\"   - Time reduction for malignant cases: {malignant_time_reduction:.2f}%\")\n",
    "    print(f\"   - Survival probability improvement for malignant cases: {malignant_survival_improvement:.2f} percentage points\")\n",
    "    \n",
    "    # Overall conclusion\n",
    "    print(\"\\nHypothesis Testing Conclusion:\")\n",
    "    if time_reduction_pct >= 66.67:  # Reduction from 72 to 24 hours is roughly 66.67%\n",
    "        print(\"✓ The data supports the hypothesis about reducing diagnostic time from 72 to 24 hours.\")\n",
    "    else:\n",
    "        print(\"✗ The data does not fully support the hypothesis about reducing diagnostic time from 72 to 24 hours.\")\n",
    "        print(f\"  Actual reduction: {time_reduction_pct:.2f}% (vs. required 66.67%)\")\n",
    "    \n",
    "    # Generate a summary table\n",
    "    summary_data = {\n",
    "        'Metric': [\n",
    "            'Average Traditional Diagnostic Time (hours)', \n",
    "            'Average AI-Assisted Diagnostic Time (hours)',\n",
    "            'Time Reduction (%)',\n",
    "            'Average Technology Readiness Score',\n",
    "            'Average Survival Probability Improvement',\n",
    "            'Average Cost Difference (%)'\n",
    "        ],\n",
    "        'Value': [\n",
    "            mean_trad_time,\n",
    "            mean_ai_time,\n",
    "            time_reduction_pct,\n",
    "            df['tech_readiness_score'].mean(),\n",
    "            df['survival_probability_improvement'].mean(),\n",
    "            df['cost_difference_percentage'].mean()\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(\"\\nSummary statistics:\")\n",
    "    print(summary_df)\n",
    "\n",
    "def correlation_analysis(df):\n",
    "    \"\"\"\n",
    "    Analyze correlations between variables\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The dataset to analyze\n",
    "    \"\"\"\n",
    "    print(\"\\n===== CORRELATION ANALYSIS =====\")\n",
    "    \n",
    "    # Select relevant numeric columns for correlation analysis\n",
    "    numeric_cols = [\n",
    "        'age_approx', 'target', 'traditional_diagnosis_time', 'ai_diagnosis_time',\n",
    "        'time_saved_percentage', 'tech_readiness_score', 'traditional_total_cost',\n",
    "        'ai_total_cost', 'cost_difference_percentage', 'traditional_survival_probability',\n",
    "        'ai_survival_probability', 'survival_probability_improvement',\n",
    "        'traditional_efficiency_score', 'ai_efficiency_score', 'efficiency_improvement'\n",
    "    ]\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "    \n",
    "    # Print correlations with target variable\n",
    "    print(\"\\nCorrelations with target variable (cancer diagnosis):\")\n",
    "    target_corr = corr_matrix['target'].sort_values(ascending=False)\n",
    "    for var, corr in target_corr.items():\n",
    "        if var != 'target':\n",
    "            print(f\"  {var}: {corr:.4f}\")\n",
    "    \n",
    "    # Print correlations with time saved percentage\n",
    "    print(\"\\nCorrelations with time saved percentage:\")\n",
    "    time_saved_corr = corr_matrix['time_saved_percentage'].sort_values(ascending=False)\n",
    "    for var, corr in time_saved_corr.items():\n",
    "        if var != 'time_saved_percentage':\n",
    "            print(f\"  {var}: {corr:.4f}\")\n",
    "    \n",
    "    # Print correlations with survival probability improvement\n",
    "    print(\"\\nCorrelations with survival probability improvement:\")\n",
    "    survival_corr = corr_matrix['survival_probability_improvement'].sort_values(ascending=False)\n",
    "    for var, corr in survival_corr.items():\n",
    "        if var != 'survival_probability_improvement':\n",
    "            print(f\"  {var}: {corr:.4f}\")\n",
    "    \n",
    "    # Print correlations with efficiency improvement\n",
    "    print(\"\\nCorrelations with efficiency improvement:\")\n",
    "    efficiency_corr = corr_matrix['efficiency_improvement'].sort_values(ascending=False)\n",
    "    for var, corr in efficiency_corr.items():\n",
    "        if var != 'efficiency_improvement':\n",
    "            print(f\"  {var}: {corr:.4f}\")\n",
    "    \n",
    "    # Print strongest overall correlations\n",
    "    print(\"\\nTop 10 strongest correlations overall:\")\n",
    "    corr_pairs = []\n",
    "    for i in range(len(numeric_cols)):\n",
    "        for j in range(i+1, len(numeric_cols)):\n",
    "            corr_value = abs(corr_matrix.iloc[i, j])\n",
    "            corr_pairs.append((numeric_cols[i], numeric_cols[j], corr_value))\n",
    "    \n",
    "    corr_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "    for var1, var2, corr in corr_pairs[:10]:\n",
    "        print(f\"  {var1} & {var2}: {corr:.4f}\")\n",
    "\n",
    "def cost_benefit_analysis(df):\n",
    "    \"\"\"\n",
    "    Perform a cost-benefit analysis of AI implementation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The dataset to analyze\n",
    "    \"\"\"\n",
    "    print(\"\\n===== COST-BENEFIT ANALYSIS =====\")\n",
    "    \n",
    "    # Calculate average costs\n",
    "    trad_cost = df['traditional_total_cost'].mean()\n",
    "    ai_cost = df['ai_total_cost'].mean()\n",
    "    cost_diff = trad_cost - ai_cost\n",
    "    \n",
    "    # Calculate average times\n",
    "    trad_time = df['traditional_diagnosis_time'].mean()\n",
    "    ai_time = df['ai_diagnosis_time'].mean()\n",
    "    time_diff = trad_time - ai_time\n",
    "    \n",
    "    # Calculate staff time savings\n",
    "    if 'traditional_staff_hours' in df.columns and 'ai_staff_hours' in df.columns:\n",
    "        staff_time_trad = df['traditional_staff_hours'].mean()\n",
    "        staff_time_ai = df['ai_staff_hours'].mean()\n",
    "        staff_time_saved = staff_time_trad - staff_time_ai\n",
    "        staff_time_saved_pct = (staff_time_saved / staff_time_trad) * 100\n",
    "    else:\n",
    "        # Estimate based on time reduction\n",
    "        time_saved_pct = (time_diff / trad_time) * 100\n",
    "        staff_time_saved_pct = time_saved_pct * 0.8  # Assumption: 80% of time saved is staff time\n",
    "    \n",
    "    # Analyze by hospital tier\n",
    "    tier_costs = df.groupby('hospital_tier')[['traditional_total_cost', 'ai_total_cost', 'cost_difference_percentage']].mean()\n",
    "    \n",
    "    # Calculate ROI by country\n",
    "    country_costs = df.groupby('country')[['traditional_total_cost', 'ai_total_cost', 'cost_difference_percentage']].mean()\n",
    "    \n",
    "    print(\"\\nOverall cost comparison:\")\n",
    "    print(f\"  Traditional method average cost: {trad_cost:.2f} EUR\")\n",
    "    print(f\"  AI-assisted method average cost: {ai_cost:.2f} EUR\")\n",
    "    print(f\"  Average cost difference: {cost_diff:.2f} EUR ({(cost_diff/trad_cost*100):.2f}%)\")\n",
    "    \n",
    "    print(\"\\nTime efficiency:\")\n",
    "    print(f\"  Traditional method average time: {trad_time:.2f} hours\")\n",
    "    print(f\"  AI-assisted method average time: {ai_time:.2f} hours\")\n",
    "    print(f\"  Average time saved: {time_diff:.2f} hours ({(time_diff/trad_time*100):.2f}%)\")\n",
    "    \n",
    "    print(\"\\nStaff resource efficiency:\")\n",
    "    print(f\"  Estimated staff time saved: {staff_time_saved_pct:.2f}%\")\n",
    "    \n",
    "    print(\"\\nCost analysis by hospital tier:\")\n",
    "    print(tier_costs)\n",
    "    \n",
    "    print(\"\\nCost analysis by country:\")\n",
    "    print(country_costs)\n",
    "    \n",
    "    # Calculate potential savings for full implementation\n",
    "    total_cases = len(df)\n",
    "    annual_cases_est = total_cases * (365 / 180)  # Assuming dataset covers ~180 days\n",
    "    total_annual_savings = cost_diff * annual_cases_est\n",
    "    \n",
    "    print(\"\\nEstimated annual cost impact:\")\n",
    "    print(f\"  Estimated annual cases: {annual_cases_est:.0f}\")\n",
    "    print(f\"  Estimated annual savings: {total_annual_savings:.2f} EUR\")\n",
    "    \n",
    "    # Cost-effectiveness analysis\n",
    "    if 'survival_probability_improvement' in df.columns:\n",
    "        avg_survival_improvement = df['survival_probability_improvement'].mean()\n",
    "        cost_per_percentage_point = cost_diff / avg_survival_improvement if avg_survival_improvement > 0 else 0\n",
    "        \n",
    "        print(\"\\nCost-effectiveness analysis:\")\n",
    "        print(f\"  Average survival probability improvement: {avg_survival_improvement:.2f} percentage points\")\n",
    "        if cost_diff > 0:\n",
    "            print(f\"  Cost per percentage point improvement: {-cost_per_percentage_point:.2f} EUR (saving)\")\n",
    "        else:\n",
    "            print(f\"  Cost per percentage point improvement: {cost_per_percentage_point:.2f} EUR (additional cost)\")\n",
    "\n",
    "def run_complete_eda():\n",
    "    \"\"\"\n",
    "    Run the complete EDA pipeline\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    df = load_data()\n",
    "    \n",
    "    # Run all analyses\n",
    "    basic_eda(df)\n",
    "    clinical_analysis(df)\n",
    "    ai_comparison_analysis(df)\n",
    "    geographic_analysis(df)\n",
    "    hypothesis_testing(df)\n",
    "    correlation_analysis(df)\n",
    "    cost_benefit_analysis(df)\n",
    "    \n",
    "    print(\"\\n===== EDA COMPLETE =====\")\n",
    "    print(\"All analyses have been completed successfully.\")\n",
    "\n",
    "# Run the analysis if this script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    run_complete_eda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ISIC 2020 dataset...\n",
      "Dataset loaded successfully with 33126 rows and 8 columns.\n",
      "\n",
      "===== BASIC DATASET INFORMATION =====\n",
      "\n",
      "First 5 rows:\n",
      "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n",
      "0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n",
      "1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n",
      "2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n",
      "3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n",
      "4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n",
      "\n",
      "  diagnosis benign_malignant  target  \n",
      "0   unknown           benign       0  \n",
      "1   unknown           benign       0  \n",
      "2     nevus           benign       0  \n",
      "3   unknown           benign       0  \n",
      "4   unknown           benign       0  \n",
      "\n",
      "Data types:\n",
      "image_name                        object\n",
      "patient_id                        object\n",
      "sex                               object\n",
      "age_approx                       float64\n",
      "anatom_site_general_challenge     object\n",
      "diagnosis                         object\n",
      "benign_malignant                  object\n",
      "target                             int64\n",
      "dtype: object\n",
      "\n",
      "Basic statistics:\n",
      "                                 count unique           top   freq       mean  \\\n",
      "image_name                       33126  33126  ISIC_9999806      1        NaN   \n",
      "patient_id                       33126   2056    IP_7279968    115        NaN   \n",
      "sex                              33061      2          male  17080        NaN   \n",
      "age_approx                     33058.0    NaN           NaN    NaN  48.870016   \n",
      "anatom_site_general_challenge    32599      6         torso  16845        NaN   \n",
      "diagnosis                        33126      9       unknown  27124        NaN   \n",
      "benign_malignant                 33126      2        benign  32542        NaN   \n",
      "target                         33126.0    NaN           NaN    NaN    0.01763   \n",
      "\n",
      "                                    std  min   25%   50%   75%   max  \n",
      "image_name                          NaN  NaN   NaN   NaN   NaN   NaN  \n",
      "patient_id                          NaN  NaN   NaN   NaN   NaN   NaN  \n",
      "sex                                 NaN  NaN   NaN   NaN   NaN   NaN  \n",
      "age_approx                     14.38036  0.0  40.0  50.0  60.0  90.0  \n",
      "anatom_site_general_challenge       NaN  NaN   NaN   NaN   NaN   NaN  \n",
      "diagnosis                           NaN  NaN   NaN   NaN   NaN   NaN  \n",
      "benign_malignant                    NaN  NaN   NaN   NaN   NaN   NaN  \n",
      "target                         0.131603  0.0   0.0   0.0   0.0   1.0  \n",
      "\n",
      "===== MISSING VALUES ANALYSIS =====\n",
      "                               Missing Values  Percentage\n",
      "image_name                                  0        0.00\n",
      "patient_id                                  0        0.00\n",
      "sex                                        65        0.20\n",
      "age_approx                                 68        0.21\n",
      "anatom_site_general_challenge             527        1.59\n",
      "diagnosis                                   0        0.00\n",
      "benign_malignant                            0        0.00\n",
      "target                                      0        0.00\n",
      "\n",
      "===== CATEGORICAL VARIABLES ANALYSIS =====\n",
      "\n",
      "Sex distribution:\n",
      "  male: 17080 (51.56%)\n",
      "  female: 15981 (48.24%)\n",
      "  Missing: 65 (0.20%)\n",
      "\n",
      "Anatomical site distribution:\n",
      "  torso: 16845 (50.85%)\n",
      "  lower extremity: 8417 (25.41%)\n",
      "  upper extremity: 4983 (15.04%)\n",
      "  head/neck: 1855 (5.60%)\n",
      "  Missing: 527 (1.59%)\n",
      "  palms/soles: 375 (1.13%)\n",
      "  oral/genital: 124 (0.37%)\n",
      "\n",
      "Diagnosis distribution:\n",
      "  unknown: 27124 (81.88%)\n",
      "  nevus: 5193 (15.68%)\n",
      "  melanoma: 584 (1.76%)\n",
      "  seborrheic keratosis: 135 (0.41%)\n",
      "  lentigo NOS: 44 (0.13%)\n",
      "  lichenoid keratosis: 37 (0.11%)\n",
      "  solar lentigo: 7 (0.02%)\n",
      "  cafe-au-lait macule: 1 (0.00%)\n",
      "  atypical melanocytic proliferation: 1 (0.00%)\n",
      "\n",
      "Benign/Malignant distribution:\n",
      "  benign: 32542 (98.24%)\n",
      "  malignant: 584 (1.76%)\n",
      "\n",
      "Target distribution:\n",
      "  0: 32542 (98.24%)\n",
      "  1: 584 (1.76%)\n",
      "\n",
      "===== NUMERICAL VARIABLES ANALYSIS =====\n",
      "\n",
      "Age statistics:\n",
      "  Count: 33058.0\n",
      "  Mean: 48.87\n",
      "  Std: 14.38\n",
      "  Min: 0.00\n",
      "  25%: 40.00\n",
      "  50% (Median): 50.00\n",
      "  75%: 60.00\n",
      "  Max: 90.00\n",
      "\n",
      "===== CROSS-TABULATION ANALYSIS =====\n",
      "\n",
      "Target distribution by sex:\n",
      "target      0     1\n",
      "sex                \n",
      "female  98.62  1.38\n",
      "male    97.87  2.13\n",
      "All     98.23  1.77\n",
      "\n",
      "Target distribution by anatomical site:\n",
      "target                             0     1\n",
      "anatom_site_general_challenge             \n",
      "head/neck                      96.01  3.99\n",
      "lower extremity                98.53  1.47\n",
      "oral/genital                   96.77  3.23\n",
      "palms/soles                    98.67  1.33\n",
      "torso                          98.47  1.53\n",
      "upper extremity                97.77  2.23\n",
      "All                            98.24  1.76\n",
      "\n",
      "Target distribution by diagnosis:\n",
      "target                                   0       1\n",
      "diagnosis                                         \n",
      "atypical melanocytic proliferation  100.00    0.00\n",
      "cafe-au-lait macule                 100.00    0.00\n",
      "lentigo NOS                         100.00    0.00\n",
      "lichenoid keratosis                 100.00    0.00\n",
      "melanoma                              0.00  100.00\n",
      "nevus                               100.00    0.00\n",
      "seborrheic keratosis                100.00    0.00\n",
      "solar lentigo                       100.00    0.00\n",
      "unknown                             100.00    0.00\n",
      "All                                  98.24    1.76\n",
      "\n",
      "Benign/Malignant vs. Target:\n",
      "target                0    1    All\n",
      "benign_malignant                   \n",
      "benign            32542    0  32542\n",
      "malignant             0  584    584\n",
      "All               32542  584  33126\n",
      "\n",
      "===== AGE DISTRIBUTION ANALYSIS =====\n",
      "\n",
      "Age group distribution:\n",
      "  0-18: 149 (0.45%)\n",
      "  19-30: 4557 (13.76%)\n",
      "  31-45: 10892 (32.88%)\n",
      "  46-60: 11334 (34.21%)\n",
      "  61-75: 5476 (16.53%)\n",
      "  76+: 648 (1.96%)\n",
      "  Missing: 70 (0.21%)\n",
      "\n",
      "Target distribution by age group:\n",
      "target         0     1\n",
      "age_group             \n",
      "0-18       98.66  1.34\n",
      "19-30      98.99  1.01\n",
      "31-45      99.05  0.95\n",
      "46-60      98.39  1.61\n",
      "61-75      96.53  3.47\n",
      "76+        90.59  9.41\n",
      "All        98.23  1.77\n",
      "\n",
      "===== PATIENT ANALYSIS =====\n",
      "\n",
      "Number of unique patients: 2056\n",
      "\n",
      "Images per patient statistics:\n",
      "  Mean: 16.11\n",
      "  Std: 15.67\n",
      "  Min: 2\n",
      "  25%: 5\n",
      "  50% (Median): 12\n",
      "  75%: 22\n",
      "  Max: 115\n",
      "\n",
      "Patients with both benign and malignant lesions: 427\n",
      "\n",
      "===== SUMMARY FOR HYPOTHESIS TESTING =====\n",
      "For research hypothesis: Implementation of standardized AI-assisted diagnostic imaging systems in EU hospitals will increase cancer detection accuracy by 15% and reduce diagnostic time from 72 to 24 hours.\n",
      "\n",
      "Relevant statistics from ISIC 2020 dataset:\n",
      "  - Total number of images: 33126\n",
      "  - Unique patients: 2056\n",
      "  - Benign cases: 32542 (98.24%)\n",
      "  - Malignant cases: 584 (1.76%)\n",
      "  - Class imbalance ratio (benign:malignant): 55.72:1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def perform_isic_eda(file_path='ISIC_2020_Training_GroundTruth.csv'):\n",
    "    \"\"\"\n",
    "    Perform a basic exploratory data analysis on the ISIC 2020 dataset\n",
    "    without any visualizations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : str\n",
    "        Path to the ISIC_2020_Training_GroundTruth.csv file\n",
    "    \"\"\"\n",
    "    print(\"Loading ISIC 2020 dataset...\")\n",
    "    \n",
    "    # Load the data\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Dataset loaded successfully with {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the dataset: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 1. Basic dataset information\n",
    "    print(\"\\n===== BASIC DATASET INFORMATION =====\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(\"\\nData types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(\"\\nBasic statistics:\")\n",
    "    print(df.describe(include='all').T)\n",
    "    \n",
    "    # 2. Missing values analysis\n",
    "    print(\"\\n===== MISSING VALUES ANALYSIS =====\")\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_percent = (missing_values / len(df)) * 100\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Values': missing_values,\n",
    "        'Percentage': missing_percent.round(2)\n",
    "    })\n",
    "    \n",
    "    print(missing_df)\n",
    "    \n",
    "    # 3. Categorical variable analysis\n",
    "    print(\"\\n===== CATEGORICAL VARIABLES ANALYSIS =====\")\n",
    "    \n",
    "    # Sex distribution\n",
    "    print(\"\\nSex distribution:\")\n",
    "    sex_counts = df['sex'].value_counts(dropna=False)\n",
    "    sex_percent = (sex_counts / len(df)) * 100\n",
    "    \n",
    "    for sex, count in sex_counts.items():\n",
    "        print(f\"  {sex if pd.notna(sex) else 'Missing'}: {count} ({sex_percent[sex]:.2f}%)\")\n",
    "    \n",
    "    # Anatomical site distribution\n",
    "    print(\"\\nAnatomical site distribution:\")\n",
    "    site_counts = df['anatom_site_general_challenge'].value_counts(dropna=False)\n",
    "    site_percent = (site_counts / len(df)) * 100\n",
    "    \n",
    "    for site, count in site_counts.items():\n",
    "        print(f\"  {site if pd.notna(site) else 'Missing'}: {count} ({site_percent[site]:.2f}%)\")\n",
    "    \n",
    "    # Diagnosis distribution\n",
    "    print(\"\\nDiagnosis distribution:\")\n",
    "    diagnosis_counts = df['diagnosis'].value_counts(dropna=False)\n",
    "    diagnosis_percent = (diagnosis_counts / len(df)) * 100\n",
    "    \n",
    "    for diagnosis, count in diagnosis_counts.items():\n",
    "        print(f\"  {diagnosis if pd.notna(diagnosis) else 'Missing'}: {count} ({diagnosis_percent[diagnosis]:.2f}%)\")\n",
    "    \n",
    "    # Benign/Malignant distribution\n",
    "    print(\"\\nBenign/Malignant distribution:\")\n",
    "    bm_counts = df['benign_malignant'].value_counts(dropna=False)\n",
    "    bm_percent = (bm_counts / len(df)) * 100\n",
    "    \n",
    "    for status, count in bm_counts.items():\n",
    "        print(f\"  {status if pd.notna(status) else 'Missing'}: {count} ({bm_percent[status]:.2f}%)\")\n",
    "    \n",
    "    # Target distribution\n",
    "    print(\"\\nTarget distribution:\")\n",
    "    target_counts = df['target'].value_counts(dropna=False)\n",
    "    target_percent = (target_counts / len(df)) * 100\n",
    "    \n",
    "    for target, count in target_counts.items():\n",
    "        print(f\"  {target if pd.notna(target) else 'Missing'}: {count} ({target_percent[target]:.2f}%)\")\n",
    "    \n",
    "    # 4. Numerical variable analysis\n",
    "    print(\"\\n===== NUMERICAL VARIABLES ANALYSIS =====\")\n",
    "    \n",
    "    # Age analysis\n",
    "    print(\"\\nAge statistics:\")\n",
    "    age_stats = df['age_approx'].describe()\n",
    "    print(f\"  Count: {age_stats['count']}\")\n",
    "    print(f\"  Mean: {age_stats['mean']:.2f}\")\n",
    "    print(f\"  Std: {age_stats['std']:.2f}\")\n",
    "    print(f\"  Min: {age_stats['min']:.2f}\")\n",
    "    print(f\"  25%: {age_stats['25%']:.2f}\")\n",
    "    print(f\"  50% (Median): {age_stats['50%']:.2f}\")\n",
    "    print(f\"  75%: {age_stats['75%']:.2f}\")\n",
    "    print(f\"  Max: {age_stats['max']:.2f}\")\n",
    "    \n",
    "    # 5. Cross-tabulation analysis\n",
    "    print(\"\\n===== CROSS-TABULATION ANALYSIS =====\")\n",
    "    \n",
    "    # Target vs. Sex\n",
    "    print(\"\\nTarget distribution by sex:\")\n",
    "    sex_target = pd.crosstab(df['sex'], df['target'], margins=True, normalize='index')\n",
    "    sex_target = sex_target.multiply(100).round(2)\n",
    "    print(sex_target)\n",
    "    \n",
    "    # Target vs. Anatomical site\n",
    "    print(\"\\nTarget distribution by anatomical site:\")\n",
    "    site_target = pd.crosstab(df['anatom_site_general_challenge'], df['target'], margins=True, normalize='index')\n",
    "    site_target = site_target.multiply(100).round(2)\n",
    "    print(site_target)\n",
    "    \n",
    "    # Target vs. Diagnosis\n",
    "    print(\"\\nTarget distribution by diagnosis:\")\n",
    "    diag_target = pd.crosstab(df['diagnosis'], df['target'], margins=True, normalize='index')\n",
    "    diag_target = diag_target.multiply(100).round(2)\n",
    "    print(diag_target)\n",
    "    \n",
    "    # Benign/Malignant vs. Target (should be perfectly correlated if benign=0, malignant=1)\n",
    "    print(\"\\nBenign/Malignant vs. Target:\")\n",
    "    bm_target = pd.crosstab(df['benign_malignant'], df['target'], margins=True)\n",
    "    print(bm_target)\n",
    "    \n",
    "    # 6. Age distribution analysis\n",
    "    print(\"\\n===== AGE DISTRIBUTION ANALYSIS =====\")\n",
    "    \n",
    "    # Age groups\n",
    "    age_bins = [0, 18, 30, 45, 60, 75, 100]\n",
    "    age_labels = ['0-18', '19-30', '31-45', '46-60', '61-75', '76+']\n",
    "    \n",
    "    df['age_group'] = pd.cut(df['age_approx'], bins=age_bins, labels=age_labels)\n",
    "    \n",
    "    # Age group distribution\n",
    "    print(\"\\nAge group distribution:\")\n",
    "    age_group_counts = df['age_group'].value_counts(dropna=False).sort_index()\n",
    "    age_group_percent = (age_group_counts / len(df)) * 100\n",
    "    \n",
    "    for age_group, count in age_group_counts.items():\n",
    "        print(f\"  {age_group if pd.notna(age_group) else 'Missing'}: {count} ({age_group_percent[age_group]:.2f}%)\")\n",
    "    \n",
    "    # Target by age group\n",
    "    print(\"\\nTarget distribution by age group:\")\n",
    "    age_target = pd.crosstab(df['age_group'], df['target'], margins=True, normalize='index')\n",
    "    age_target = age_target.multiply(100).round(2)\n",
    "    print(age_target)\n",
    "    \n",
    "    # 7. Patient analysis\n",
    "    print(\"\\n===== PATIENT ANALYSIS =====\")\n",
    "    \n",
    "    # Number of unique patients\n",
    "    unique_patients = df['patient_id'].nunique()\n",
    "    print(f\"\\nNumber of unique patients: {unique_patients}\")\n",
    "    \n",
    "    # Images per patient\n",
    "    images_per_patient = df.groupby('patient_id').size().describe()\n",
    "    print(\"\\nImages per patient statistics:\")\n",
    "    print(f\"  Mean: {images_per_patient['mean']:.2f}\")\n",
    "    print(f\"  Std: {images_per_patient['std']:.2f}\")\n",
    "    print(f\"  Min: {images_per_patient['min']:.0f}\")\n",
    "    print(f\"  25%: {images_per_patient['25%']:.0f}\")\n",
    "    print(f\"  50% (Median): {images_per_patient['50%']:.0f}\")\n",
    "    print(f\"  75%: {images_per_patient['75%']:.0f}\")\n",
    "    print(f\"  Max: {images_per_patient['max']:.0f}\")\n",
    "    \n",
    "    # Patients with both benign and malignant lesions\n",
    "    patient_has_benign = df[df['benign_malignant'] == 'benign']['patient_id'].unique()\n",
    "    patient_has_malignant = df[df['benign_malignant'] == 'malignant']['patient_id'].unique()\n",
    "    patients_with_both = set(patient_has_benign).intersection(set(patient_has_malignant))\n",
    "    \n",
    "    print(f\"\\nPatients with both benign and malignant lesions: {len(patients_with_both)}\")\n",
    "    \n",
    "    # 8. Summary analysis for research hypothesis\n",
    "    print(\"\\n===== SUMMARY FOR HYPOTHESIS TESTING =====\")\n",
    "    print(\"For research hypothesis: Implementation of standardized AI-assisted diagnostic imaging systems in EU hospitals will increase cancer detection accuracy by 15% and reduce diagnostic time from 72 to 24 hours.\")\n",
    "    \n",
    "    print(\"\\nRelevant statistics from ISIC 2020 dataset:\")\n",
    "    print(f\"  - Total number of images: {len(df)}\")\n",
    "    print(f\"  - Unique patients: {unique_patients}\")\n",
    "    print(f\"  - Benign cases: {len(df[df['benign_malignant'] == 'benign'])} ({len(df[df['benign_malignant'] == 'benign'])/len(df)*100:.2f}%)\")\n",
    "    print(f\"  - Malignant cases: {len(df[df['benign_malignant'] == 'malignant'])} ({len(df[df['benign_malignant'] == 'malignant'])/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    # Calculate class imbalance ratio\n",
    "    imbalance_ratio = len(df[df['benign_malignant'] == 'benign']) / len(df[df['benign_malignant'] == 'malignant'])\n",
    "    print(f\"  - Class imbalance ratio (benign:malignant): {imbalance_ratio:.2f}:1\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    perform_isic_eda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired t-test for Traditional vs AI Diagnostic Time\n",
      "t-statistic: 594.4919\n",
      "p-value: 0.00000000\n",
      "Mean traditional time: 69.05 hours\n",
      "Mean AI time: 23.60 hours\n",
      "Mean difference: 45.45 hours\n",
      "Percentage reduction: 65.82%\n",
      "Statistical significance: Significant\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('complete_cancer_detection_dataset.csv')\n",
    "\n",
    "# Perform paired t-test on traditional vs AI diagnostic times\n",
    "t_stat, p_value = stats.ttest_rel(df['traditional_diagnosis_time'], df['ai_diagnosis_time'])\n",
    "\n",
    "print(\"Paired t-test for Traditional vs AI Diagnostic Time\")\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.8f}\")\n",
    "print(f\"Mean traditional time: {df['traditional_diagnosis_time'].mean():.2f} hours\")\n",
    "print(f\"Mean AI time: {df['ai_diagnosis_time'].mean():.2f} hours\")\n",
    "print(f\"Mean difference: {(df['traditional_diagnosis_time'] - df['ai_diagnosis_time']).mean():.2f} hours\")\n",
    "print(f\"Percentage reduction: {((df['traditional_diagnosis_time'] - df['ai_diagnosis_time']).mean() / df['traditional_diagnosis_time'].mean() * 100):.2f}%\")\n",
    "print(f\"Statistical significance: {'Significant' if p_value < 0.05 else 'Not significant'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
